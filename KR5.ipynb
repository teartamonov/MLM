{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "936dafcf-5842-4573-b657-82ab26a8f674",
   "metadata": {},
   "source": [
    "### РОССИЙСКИЙ УНИВЕРСИТЕТ ДРУЖБЫ НАРОДОВ\n",
    "\n",
    "#### Факультет физико-математических и естественных наук  \n",
    "#### Кафедра математического моделирования и искусственного интеллекта "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8633db-4f26-47a5-ad22-1c60a21d4b6c",
   "metadata": {},
   "source": [
    "## ОТЧЕТ ПО КОНТРОЛЬНОЙ РАБОТЕ № 5\n",
    "\n",
    "\n",
    "### Дисциплина: Методы машинного обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349939aa-5c5a-4e40-ac71-29a1bdf413f0",
   "metadata": {},
   "source": [
    "## Москва 2024\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2550caef-a20a-4c51-b902-b12975f6e33b",
   "metadata": {},
   "source": [
    "##### Студент:  Артамонов Т.Е.\n",
    "##### Группа:   НКНбд-01-21"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91496333-13b3-4816-9607-9dfa5cbdf4d4",
   "metadata": {},
   "source": [
    "Контрольная работа 5 Вариант 14 \n",
    "\n",
    "1. Набор данных stl10 \n",
    "2. Классы с метками 4,5,6 \n",
    "3. Требования к архитектуре сети MLP: \n",
    "Кол-во скрытых слоев 5 \n",
    "Кол-во нейронов 50 в каждом нечетном скрытом слое, 70 в каждом четном скрытом слое \n",
    "Оптимизатор Adamax \n",
    "Функция активации в скрытых слоях elu \n",
    "Регуляризация L1 в каждом нечетном скрытом слое \n",
    "4. Требования к архитектуре сети CNN: \n",
    "Кол-во слоев пулинга 4 \n",
    "Количество фильтров в сверточных слоях 8 \n",
    "Размеры фильтра 5х5 \n",
    "Оптимизатор Adafactor \n",
    "Функция активации в сверточных слоях tanh \n",
    "Функция активации в скрытых плотных слоях selu \n",
    "Регуляризация L2 в каждом скрытом плотном слое \n",
    "5. Показатель качества бинарной классификации: \n",
    "индекс Жаккара, равный TP/(TP + FP + FN) \n",
    "6. Показатель качества многоклассовой классификации: \n",
    "средняя точность классов, где точность (precision) класса равна доле правильных предсказаний для всех точек, относимых классификатором к этому классу. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec86897-cb51-43bf-9fcd-500791d557ad",
   "metadata": {},
   "source": [
    "### Задание 1. Загрузите заданный в индивидуальном задании набор данных с изображениями из Tensorflow Datasets с разбиением на обучающую и тестовую выборки."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c8da55-ddad-4b10-b52d-adcbafc33db3",
   "metadata": {},
   "source": [
    "### Решение\n",
    "Импортируем библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c5a67ff-1774-4961-9dd2-09cd8ea254fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from PIL import Image, ImageOps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a746dec-6c73-41de-a551-424cc7bf175b",
   "metadata": {},
   "source": [
    "Загрузим тренировочную и тестовую части датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24f4090-7cb8-4649-8c2b-aa9149dcc439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to C:\\Users\\artam\\tensorflow_datasets\\stl10\\1.0.0...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffc43a0979e1438aa25e5f3d71edae44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Completed...: 0 url [00:00, ? url/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e8979b56cd7429bb7d3d2a67eb046b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Size...: 0 MiB [00:00, ? MiB/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d798756a3e37492fb0ea401ffea9d8f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extraction completed...: 0 file [00:00, ? file/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds = tfds.load(\"stl10\", split=['train', 'test'])\n",
    "df_train = tfds.as_dataframe(ds[0])\n",
    "df_test = tfds.as_dataframe(ds[1])\n",
    "df_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c96f4e-bb75-4f84-b7b7-a167505e66d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed616d3-0ea9-4bf6-8d7a-0fc0b0203d69",
   "metadata": {},
   "source": [
    "### Задание 2.  Визуализируйте несколько изображений, отобранных случайным образом из обучающей выборки."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452eee16-d86b-4c54-b89c-30568b21aa10",
   "metadata": {},
   "source": [
    "### Решение"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cdf6f79-ae6a-456e-b472-30416513326e",
   "metadata": {},
   "source": [
    "Выведем несколько случайных изображений из датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6dd9005-01d8-416a-8de8-e350005b1786",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def plot_random_sample(images):\n",
    "    n = 10\n",
    "    imgs = random.sample(list(images), n)\n",
    "\n",
    "    num_row = 2\n",
    "    num_col = 5\n",
    "\n",
    "    fig, axes = plt.subplots(num_row, num_col, figsize=(3.5 * num_col, 3 * num_row))\n",
    "    # For every image\n",
    "    for i in range(num_row * num_col):\n",
    "        # Read the image\n",
    "        img = imgs[i]\n",
    "        # Display the image\n",
    "        ax = axes[i // num_col, i % num_col]\n",
    "        ax.imshow(img)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37498899-8c95-4073-8dc2-04f3d50d36cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_random_sample(df_train['image'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb52034-2a10-443b-9f50-88792c8d6ee3",
   "metadata": {},
   "source": [
    "### Задание 3. Оставьте в наборе изображения двух классов, указанных в индивидуальном задании первыми. Обучите нейронные сети MLP и CNN задаче бинарной классификации изображений (требования к архитектуре сетей указаны в индивидуальном задании). Отследите обучение нейронных сетей и укажите, на сколько процентов снизились в результате обучения потери по отношению к потерям на первой эпохе обучения. Оцените результаты обучения нейронных сетей (варианты: нейронная сеть обучилась, недообучилась, переобучилась)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3616a20d-9312-4867-bf3a-3f8895a8333e",
   "metadata": {},
   "source": [
    "### Решение"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee659a2-d952-4831-a5d7-62104f53109a",
   "metadata": {},
   "source": [
    "Выберем из датасета только изображения с метками 4 и 5, заменим эти метки на 0 и 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdd802a-cafb-474e-be20-066b4eff9d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_train[df_train['label'] == 4]\n",
    "x['label'] = 0\n",
    "y = df_train[df_train['label'] == 5]\n",
    "y['label'] = 1\n",
    "df_tr1 = pd.concat([x, y])\n",
    "\n",
    "\n",
    "x = df_test[df_test['label'] == 4]\n",
    "x['label'] = 0\n",
    "y = df_test[df_test['label']  == 5]\n",
    "y['label'] = 1\n",
    "\n",
    "df_te1 = pd.concat([x, y])\n",
    "\n",
    "df_tr1['label'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7a5d56-9501-4b98-b0e5-32495433e655",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_te1['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217c8986-e272-4483-ba9c-58a7d0abfaec",
   "metadata": {},
   "source": [
    "Изображения 96х96 пикселей с rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58950cd-8fe9-40bf-87e9-f6ae6f6be591",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.iloc[0]['image'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0829300d-70f0-4ae2-9a17-38e3b721358e",
   "metadata": {},
   "source": [
    "Проверим, что все распределилось правильно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4162ea7-06f8-46e4-927b-24d0acc40d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_random_sample(df_te1['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d51b456-5a4a-4fd9-a406-32e7bfb05987",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_random_sample(df_tr1['image'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85eed3b9-1a81-4dad-851a-27c76771329c",
   "metadata": {},
   "source": [
    "В классах 4 и 5 олени и собаки"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a285257-5848-4789-86b1-ea8d4d6eea9e",
   "metadata": {},
   "source": [
    "Предобработаем данные из датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effa605c-1c93-41e8-8cdc-9eb5a4bf2a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = df_tr1['label'].to_numpy(dtype=np.float32)\n",
    "test_labels = df_te1['label'].to_numpy(dtype=np.float32)\n",
    "train_images = np.zeros(shape=(df_tr1.shape[0],96,96,3), dtype=np.float32)\n",
    "test_images  = np.zeros(shape=(df_te1.shape[0],96,96,3), dtype=np.float32)\n",
    "\n",
    "for idx in range(train_labels.shape[0]):\n",
    "    train_images[idx,:,:,:] = \\\n",
    "        np.array(Image.fromarray(df_tr1.iloc[idx]['image']))\n",
    "\n",
    "for idx in range(test_labels.shape[0]):\n",
    "    test_images[idx,:,:,:] = \\\n",
    "        np.array(Image.fromarray(df_te1.iloc[idx]['image']))\n",
    "    \n",
    "train_images /= 255\n",
    "test_images  /= 255\n",
    "\n",
    "train_images.shape, test_images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf7e581-11d4-45b1-94a6-6b1b1abd7cd5",
   "metadata": {},
   "source": [
    "Создадим модель MLP и обучим ее соответственно заданию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3daad59b-6689-4c14-acf5-89e1f134caa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "model_1 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(96, 96, 3)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(50, activation='elu', kernel_regularizer='l1'),\n",
    "    tf.keras.layers.Dense(70, activation='elu'),\n",
    "    tf.keras.layers.Dense(50, activation='elu', kernel_regularizer='l1'),\n",
    "    tf.keras.layers.Dense(70, activation='elu'),\n",
    "    tf.keras.layers.Dense(50, activation='elu', kernel_regularizer='l1'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_1.compile(\n",
    "    loss=tf.keras.losses.binary_crossentropy,\n",
    "    optimizer=tf.keras.optimizers.Adamax(0.00008),\n",
    "    metrics=[tf.keras.metrics.BinaryAccuracy(name='accuracy')]\n",
    ")\n",
    "\n",
    "history_1 = model_1.fit(\n",
    "    train_images,\n",
    "    train_labels,\n",
    "    epochs=100,\n",
    "    batch_size=128,\n",
    "    validation_data=(test_images, test_labels)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ebbefb4-2a79-4fbe-ae2a-86f0f1d2bd39",
   "metadata": {},
   "source": [
    "Модель переобучилась, точность упала"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa779f62-560d-4df9-b8d5-74108bc1584d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "model_2 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(filters=8, kernel_size=(5, 5),\n",
    "                           activation='tanh'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2, 2), padding='same'),\n",
    "    tf.keras.layers.Conv2D(filters=8, kernel_size=(5, 5),\n",
    "                           activation='tanh'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2, 2), padding='same'),\n",
    "\n",
    "    tf.keras.layers.Conv2D(filters=8, kernel_size=(5, 5),\n",
    "                           activation='tanh'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2, 2), padding='same'),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(filters=8, kernel_size=(5, 5),\n",
    "                           activation='tanh'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2, 2), padding='same'),\n",
    "\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dropout(rate=0.3),\n",
    "    tf.keras.layers.Dense(128, activation='selu', kernel_regularizer='l2'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_2.compile(\n",
    "    loss=tf.keras.losses.binary_crossentropy,\n",
    "    optimizer=tf.keras.optimizers.Adafactor(),\n",
    "    metrics=[tf.keras.metrics.BinaryAccuracy(name='accuracy')]\n",
    ")\n",
    "\n",
    "history_2 = model_2.fit(\n",
    "    train_images,\n",
    "    train_labels,\n",
    "    epochs=100,\n",
    "    batch_size=128,\n",
    "    validation_data=(test_images, test_labels)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0277c1b-5e7a-4631-9aaf-a7786d5ba784",
   "metadata": {},
   "source": [
    "Модель переобучилась, разница между потерями в тренировочной и тестовой выборке увеличивается"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9e4b60-9d54-4b50-98b6-df682fce3720",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Снижение потерь модели MLP на\",(1 - history_1.history['loss'][-1] / history_1.history['loss'][0])*100,'%')\n",
    "print(\"Снижение потерь модели CNN на\", (1 - history_2.history['loss'][-1] / history_2.history['loss'][0])*100,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939d7b37-a3cc-40b7-a05c-b7cbd1704cde",
   "metadata": {},
   "source": [
    "### Задание 4. Постройте кривые обучения нейронных сетей бинарной классификации для показателей потерь и доли верных ответов в зависимости от эпохи обучения, подписывая оси и рисунок и создавая легенду. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbf6bf6-7518-47a8-9fa5-4dc27f3d3e3e",
   "metadata": {},
   "source": [
    "### Решение\n",
    "Построим для первой модели 2 разных графика для потерь и доли верных ответов, т.к. размеры графиков сильно отличаются"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bd1718-bd5b-4698-9798-f4a126264b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(1, 101), history_1.history['loss'], label='Training Loss')\n",
    "plt.plot(np.arange(1, 101), history_1.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training vs. Validation Loss', size=20)\n",
    "plt.xlabel('Epoch', size=14)\n",
    "plt.ylabel('Loss', size=14)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665e4361-c79d-4388-8067-32895879b44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(1, 101), history_1.history['accuracy'], label='Accuracy')\n",
    "plt.plot(np.arange(1, 101), history_1.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Training vs. Validation Accuracy', size=20)\n",
    "plt.xlabel('Epoch', size=14)\n",
    "plt.ylabel('Accuracy', size=14)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb72ff9-9f81-4a9e-835b-6a764b8aefa8",
   "metadata": {},
   "source": [
    "Видно, что точность после 70 эпохи начинает падать"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a449c9-40ae-457d-88c9-40f5f3c33453",
   "metadata": {},
   "source": [
    "Построим график для второй модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997797c5-33a2-4a05-8b65-62679783e961",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(1, 101), history_2.history['loss'], label='Training Loss')\n",
    "plt.plot(np.arange(1, 101), history_2.history['val_loss'], label='Validation Loss')\n",
    "plt.plot(np.arange(1, 101), history_2.history['accuracy'], label='Accuracy')\n",
    "plt.plot(np.arange(1, 101), history_2.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Training vs. Validation loss and accuracy', size=20)\n",
    "plt.xlabel('Epoch', size=14)\n",
    "plt.ylabel('Loss', size=14)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6fbf3fe-820c-44a6-9d9e-18bbc777775d",
   "metadata": {},
   "source": [
    "Видно, что линии функций тренировочных и валидационных данных начинают расходиться, это свидетельствует о переобучении"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50d3efd-7929-4fa8-a51e-ccdbdc908980",
   "metadata": {},
   "source": [
    "### Задание 5. Сравните качество бинарной классификации нейронными сетями при помощи показателя качества, указанного в индивидуальном задании."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f4cfc9-46a0-49a1-87c6-372093b49a54",
   "metadata": {},
   "source": [
    "### Решение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9330f6ea-c484-4c9f-aa3c-9a1a3b332bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jk(y_true, y_predict):\n",
    "    assert len(y_true) == len(y_predict)\n",
    "    tp = np.sum((y_true == 0) & (y_predict == 0))\n",
    "    fp = np.sum((y_true == 0) & (y_predict == 1))\n",
    "    fn = np.sum((y_true == 1) & (y_predict == 0))\n",
    "    return tp/(tp + fn + fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe90907b-3968-4ea3-93fe-4d4f6249535e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = np.array([1 if prob > 0.5 else 0 for prob in np.ravel(model_1.predict(train_images))])\n",
    "y2 = np.array([1 if prob > 0.5 else 0 for prob in np.ravel(model_2.predict(train_images))])\n",
    "print(\"Индекс Жаккара для первой модели:\", jk(y1, np.array(train_labels))) \n",
    "print(\"Индекс Жаккара для второй модели:\", jk(y2, np.array(train_labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ad2f5e-ff11-4865-8606-42c70027f2e3",
   "metadata": {},
   "source": [
    "Показатель второй модели гораздо выше"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ddeaf9-10ce-40b8-9afa-88818a4d7299",
   "metadata": {},
   "source": [
    "### Задание 6. Визуализируйте ROC-кривые для построенных классификаторов на одном рисунке (с легендой) и вычислите площади под ROC-кривыми."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b48260-7d57-4941-8bb5-62a30d82a179",
   "metadata": {},
   "source": [
    "### Решение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d481b5b2-b162-4fc0-b23e-6d8f11c0de42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def true_false_positive(threshold_vector, y_test):\n",
    "    true_positive = np.equal(threshold_vector, 1) & np.equal(y_test, 1)\n",
    "    true_negative = np.equal(threshold_vector, 0) & np.equal(y_test, 0)\n",
    "    false_positive = np.equal(threshold_vector, 1) & np.equal(y_test, 0)\n",
    "    false_negative = np.equal(threshold_vector, 0) & np.equal(y_test, 1)\n",
    "\n",
    "    tpr = true_positive.sum() / (true_positive.sum() + false_negative.sum())\n",
    "    fpr = false_positive.sum() / (false_positive.sum() + true_negative.sum())\n",
    "\n",
    "    return tpr, fpr\n",
    "def roc_from_scratch(probabilities, y_test, partitions=100):\n",
    "    roc = np.array([])\n",
    "    for i in range(partitions + 1):\n",
    "\n",
    "        threshold_vector = np.greater_equal(probabilities, i / partitions).astype(int)\n",
    "        tpr, fpr = true_false_positive(threshold_vector, y_test)\n",
    "        roc = np.append(roc, [fpr, tpr])\n",
    "\n",
    "    return roc.reshape(-1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52c3bd6-c072-4a7c-b9a3-ec91b3295bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "plt.figure(figsize=(15,7))\n",
    "m1 = model_1.predict(train_images)\n",
    "m2 = model_2.predict(train_images)\n",
    "r1 = roc_auc_score(train_labels, m1)\n",
    "r2 = roc_auc_score(train_labels, m2)\n",
    "ROC1 = roc_from_scratch(m1.reshape(-1),train_labels,partitions=50)\n",
    "plt.plot(ROC1[:,0],ROC1[:,1],lw=5, label='Model 1, ROC AUC=' + str(r1))\n",
    "\n",
    "ROC2 = roc_from_scratch(m2.reshape(-1),train_labels,partitions=50)\n",
    "plt.plot(ROC2[:,0],ROC2[:,1],lw=5, label='Model 2, ROC AUC=' + str(r2))\n",
    "\n",
    "plt.title('ROC кривая',fontsize=20)\n",
    "plt.xlabel('Показатель FPR (False Positive Rate)',fontsize=16)\n",
    "plt.ylabel('Показатель TPR (True Positive Rate)',fontsize=16)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c97f337-2940-4463-8454-69308b2bebb9",
   "metadata": {},
   "source": [
    "Площадь под кривой второй модели лучше"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68c629d-50b5-48a0-a352-e8d1d61a167e",
   "metadata": {},
   "source": [
    "### Задание 7. Оставьте в наборе изображения трех классов, указанных в индивидуальном задании. Обучите нейронные сети MLP и CNN задаче многоклассовой классификации изображений (требования к архитектуре сетей указаны в индивидуальном задании)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93319ee3-99df-4d2e-be77-f4c839092031",
   "metadata": {},
   "source": [
    "### Решение\n",
    "Оставим в наборе изображения с метками 4, 5, 6, переименуем их в 0, 1, 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2c7dd8-69c1-4568-8c34-14e32ae46dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_train[df_train['label'] == 4]\n",
    "x['label'] = 0\n",
    "y = df_train[df_train['label'] == 5]\n",
    "y['label'] = 1\n",
    "z = df_train[df_train['label'] == 6]\n",
    "z['label'] = 2\n",
    "\n",
    "df_tr2 = pd.concat([x, y, z])\n",
    "\n",
    "x = df_test[df_test['label'] == 4]\n",
    "x['label'] = 0\n",
    "y = df_test[df_test['label']  == 5]\n",
    "y['label'] = 1\n",
    "z = df_test[df_test['label']  == 6]\n",
    "z['label'] = 2\n",
    "\n",
    "df_te2 = pd.concat([x, y, z])\n",
    "\n",
    "df_tr2['label'].value_counts(), df_te2['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38df2676-3930-415d-b74a-ba2012b18afd",
   "metadata": {},
   "source": [
    "Применим one-hot encoding для меток, предобработаем данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a46fc6c-431c-4140-a0d3-a79fcfca6594",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y1 = list(df_tr2['label'])\n",
    "for i in range(len(Y1)):\n",
    "    tmp = [0]*3\n",
    "    tmp[Y1[i]] = 1\n",
    "    Y1[i] = tmp\n",
    "\n",
    "Y2 = list(df_te2['label'])\n",
    "for i in range(len(Y2)):\n",
    "    tmp = [0]*3\n",
    "    tmp[Y2[i]] = 1\n",
    "    Y2[i] = tmp\n",
    "\n",
    "train_labels = np.array(Y1, dtype=np.float32)\n",
    "test_labels = np.array(Y2, dtype=np.float32)\n",
    "\n",
    "\n",
    "train_images = np.zeros(shape=(df_tr2.shape[0],96,96,3), dtype=np.float32)\n",
    "test_images  = np.zeros(shape=(df_te2.shape[0],96,96,3), dtype=np.float32)\n",
    "\n",
    "for idx in range(train_labels.shape[0]):\n",
    "    train_images[idx,:,:,:] = \\\n",
    "        np.array(Image.fromarray(df_tr2.iloc[idx]['image']))\n",
    "\n",
    "for idx in range(test_labels.shape[0]):\n",
    "    test_images[idx,:,:,:] = \\\n",
    "        np.array(Image.fromarray(df_te2.iloc[idx]['image']))\n",
    "    \n",
    "train_images /= 255\n",
    "test_images  /= 255\n",
    "\n",
    "train_images.shape, test_images.shape, train_labels.shape, test_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2319e30a-be14-4af4-b238-483ffa5f6cea",
   "metadata": {},
   "source": [
    "Создадим и обучим модель MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eebba93-3337-4189-b82b-c0c49a01a5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "model_3 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(96, 96, 3)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(50, activation='elu', kernel_regularizer='l1'),\n",
    "    tf.keras.layers.Dense(70, activation='elu'),\n",
    "    tf.keras.layers.Dense(50, activation='elu', kernel_regularizer='l1'),\n",
    "    tf.keras.layers.Dense(70, activation='elu'),\n",
    "    tf.keras.layers.Dense(50, activation='elu', kernel_regularizer='l1'),\n",
    "    tf.keras.layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "model_3.compile(\n",
    "    loss=tf.keras.losses.categorical_crossentropy,\n",
    "    optimizer=tf.keras.optimizers.Adamax(0.00005),\n",
    "    metrics=[tf.keras.metrics.CategoricalAccuracy(name='accuracy')]\n",
    ")\n",
    "\n",
    "history_3 = model_3.fit(\n",
    "    train_images,\n",
    "    train_labels,\n",
    "    epochs=100,\n",
    "    batch_size=128,\n",
    "    validation_data=(test_images, test_labels)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524a3c77-c565-4c82-abb0-279c75898bf3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3711d2-4e49-4f1b-beb3-04b5f8982790",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "model_4 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(filters=8, kernel_size=(5, 5),\n",
    "                           activation='tanh'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2, 2), padding='same'),\n",
    "    tf.keras.layers.Conv2D(filters=8, kernel_size=(5, 5),\n",
    "                           activation='tanh'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2, 2), padding='same'),\n",
    "\n",
    "    tf.keras.layers.Conv2D(filters=8, kernel_size=(5, 5),\n",
    "                           activation='tanh'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2, 2), padding='same'),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(filters=8, kernel_size=(5, 5),\n",
    "                           activation='tanh'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2, 2), padding='same'),\n",
    "\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dropout(rate=0.3),\n",
    "    tf.keras.layers.Dense(128, activation='selu', kernel_regularizer='l2'),\n",
    "    tf.keras.layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "model_4.compile(\n",
    "    loss=tf.keras.losses.categorical_crossentropy,\n",
    "    optimizer=tf.keras.optimizers.Adafactor(),\n",
    "    metrics=[tf.keras.metrics.CategoricalAccuracy(name='accuracy')]\n",
    ")\n",
    "\n",
    "history_4 = model_4.fit(\n",
    "    train_images,\n",
    "    train_labels,\n",
    "    epochs=100,\n",
    "    batch_size=128,\n",
    "    validation_data=(test_images, test_labels)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169c6c51-174a-487a-ad5e-cc27294bbdc3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4ea99b1e-3631-4f38-97d7-6ee89c1d6f26",
   "metadata": {},
   "source": [
    "### 8. Сравните качество многоклассовой классификации нейронными сетями при помощи показателя качества, указанного в индивидуальном задании."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b08ef6-ae0d-4b17-ba83-948fe499594a",
   "metadata": {},
   "source": [
    "### Решение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe01aa3-672c-4ede-9866-c83aedd54a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = tf.keras.metrics.Precision()\n",
    "m.update_state(train_labels, model_3.predict(train_images))\n",
    "x1 = m.result().numpy()\n",
    "m.reset_state()\n",
    "m.update_state(train_labels, model_4.predict(train_images))\n",
    "x2 = m.result().numpy()\n",
    "print(\"Precision первой модели:\", x1) \n",
    "print(\"Precision второй модели:\", x2) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7612868-1e44-4ff5-9991-f82ed7b5363b",
   "metadata": {},
   "source": [
    "У первой модели показатель качества выше"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa9117c-7c76-49c2-a993-24e893d41e26",
   "metadata": {},
   "source": [
    "### Задание 9. Постройте кривые обучения нейронных сетей многоклассовой классификации для показателей ошибки и доли верных ответов в зависимости от эпохи обучения, подписывая оси и рисунок и создавая легенду. Сопроводите программный код необходимыми комментариями."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746f5521-614d-4766-9394-2c838de75b75",
   "metadata": {},
   "source": [
    "### Решение\n",
    "Для первой модели два графика, т.к. размеры отличаются"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e292237-b309-4b95-9a15-9932f7f5e9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(1, 101), history_3.history['loss'], label='Training Loss')\n",
    "plt.plot(np.arange(1, 101), history_3.history['val_loss'], label='Validation Loss')\n",
    "\n",
    "plt.title('Model 1 Training vs. Validation loss', size=18)\n",
    "plt.xlabel('Epoch', size=14)\n",
    "plt.ylabel('Loss', size=14)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa1c27d-37b3-4baf-94fd-41e7b71db04d",
   "metadata": {},
   "source": [
    "Если судить по показателю потерь, то все хорошо"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca80c4c-711a-4ab9-932d-db36b9090b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(1, 101), history_3.history['accuracy'], label='Accuracy')\n",
    "plt.plot(np.arange(1, 101), history_3.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model 1 Training vs. Validation accuracy', size=18)\n",
    "plt.xlabel('Epoch', size=14)\n",
    "plt.ylabel('Accuracy', size=14)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2863588b-bd18-4106-a7ee-8269ae98e7ea",
   "metadata": {},
   "source": [
    "Но показатели метрики падают, модель переобучилась"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697d4a78-b867-4fb4-83d6-9ccb10ff0e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(1, 101), history_4.history['loss'], label='Training Loss')\n",
    "plt.plot(np.arange(1, 101), history_4.history['val_loss'], label='Validation Loss')\n",
    "plt.plot(np.arange(1, 101), history_4.history['accuracy'], label='Accuracy')\n",
    "plt.plot(np.arange(1, 101), history_4.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model 2 Training vs. Validation loss and accuracy', size=18)\n",
    "plt.xlabel('Epoch', size=14)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffffd8e9-367f-4030-9d9c-ceeb4fa97f48",
   "metadata": {},
   "source": [
    "Видно, что постепенно разница между Training и Validation растёт, модель переобучилась."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10de817-6a9a-4908-baa5-d22377ba771f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myfuckingwnviroment",
   "language": "python",
   "name": "myfuckingwnviroment"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
